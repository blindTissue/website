# Pursuing BS/MsE in Computer Science and AMS at the Johns Hopkins University

## Research experience
- **Research Assistant** at [Center for Language and Speech Processing](https://www.clsp.jhu.edu/) (CLSP) under Prof. Mark Dredze, Johns Hopkins University, 2023 - present
- **Reserach Assistnat** at Johns Hopkins University working on Neural Network-derived perfusion maps for isometric stroke under Prof. Craig Jones, 2023-present 

## Education
- **Johns Hopkins University**, Baltimore, MD, 2018 - 2020, 2022 - present
  - BS/MsE in Computer Science and Applied Mathematics and Statistics
  - GPA: 3.89/4.0 (4.0 / 4.0 on 400+ level courses)
  - Honors: Dean's List (2018-present)



## Projects

- **Exploration of Position Embedding Methods and Attention Mechanism on Small Scale Transformer Classifiers**
  - The Attention is All You Need paper, published in 2017 uses a sinusodial position embedding. Shortly after, different position embedding schemes including learned position embedding, relative position embedding, AliBi and more has been proposed. However, these schemes are compared with the state of the art models such as T5 or GPT3 on benchmarks. In this project, we explore the performance of different position embedding schemes on small scale transformers which are runable on a single GPU.
  - We also delve into different and perhaps noble attention mechanisms such as narrowing attention and denser attention.
  - The code is available [here](https://github.com/blindTissue/NLP-Project).
  - results are viewable [here](https://www.overleaf.com/read/qntmwnjwpdrr).

- **Pokemon Type Ranking Calculator**
    - Not all Pokemon Types are made equal. Some types are more offensive while others are more defensive, and others, balanced. There has been various rankings of Pokemon types but they include additional information as abilities, distributed moves, and stats. In this short script, I rank Pokemon types based on type effectiveness only with reasonable constraints.

- **Neural Style Transfer**
    - Neural Style Transfer is a technique that takes two images, a content image and a style image, and combines them such that the output image looks like the content image but painted in the style of the style image. In this group project, we modify the method suggested in [Gatys et al.](https://arxiv.org/pdf/1508.06576.pdf) by adding additional loss metrics and using a different pretrained model. We also explore the effect of different hyperparameters on the output image.


  
 
